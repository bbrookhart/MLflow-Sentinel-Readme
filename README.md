<div align="center">

<img src="docs/assets/banner.svg" alt="MLflow-Sentinel Banner" width="100%"/>

# MLflow-Sentinel

**Production ML Pipeline Observability â€” From Training to Drift**

[![CI](https://github.com/yourusername/mlflow-sentinel/actions/workflows/ci.yml/badge.svg)](https://github.com/yourusername/mlflow-sentinel/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/yourusername/mlflow-sentinel/branch/main/graph/badge.svg)](https://codecov.io/gh/yourusername/mlflow-sentinel)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/docker-ready-2496ED?logo=docker&logoColor=white)](docker/docker-compose.yml)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[**Live Demo**](https://mlflow-sentinel-demo.vercel.app) Â· [**Docs**](docs/) Â· [**Architecture**](#architecture) Â· [**Quickstart**](#quickstart)

</div>

---

## The Problem

You trained a great model. MLflow tracked every run. You shipped it.

Then, silently â€” the data distribution shifted. Predictions degraded. You found out from a user complaint three weeks later.

**MLflow-Sentinel closes that gap.**

It connects your MLflow tracking server to a real-time observability layer: ingesting training run metadata, monitoring live prediction logs, detecting statistical data drift, and surfacing everything in a single operations dashboard â€” so your team knows the moment something goes wrong, not weeks after.

---

## What It Does

| Capability | Description |
|---|---|
| ðŸ”„ **Pipeline Ingestion** | Polls MLflow runs, experiment metadata, and artifact manifests on a configurable schedule |
| ðŸ“Š **Drift Detection** | Runs PSI, KS-test, and Jensen-Shannon divergence against your training baseline |
| ðŸš¨ **Alerting** | Webhook-native alerting to Slack, PagerDuty, or any HTTP endpoint |
| ðŸ“¡ **REST API** | FastAPI backend exposing all metrics with OpenAPI docs at `/docs` |
| ðŸ–¥ï¸ **Live Dashboard** | React + Recharts dashboard with WebSocket-powered real-time updates |
| ðŸ—ƒï¸ **Storage Adapters** | Pluggable backends â€” SQLite for local dev, PostgreSQL for production |
| ðŸ³ **Docker-first** | One command to run the entire stack locally |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MLflow-Sentinel                             â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Ingestion  â”‚â”€â”€â”€â–¶â”‚Transformationâ”‚â”€â”€â”€â–¶â”‚   Storage Layer      â”‚  â”‚
â”‚  â”‚   Engine     â”‚    â”‚  & Drift     â”‚    â”‚  (SQLite/PostgreSQL)  â”‚  â”‚
â”‚  â”‚              â”‚    â”‚  Detection   â”‚    â”‚                      â”‚  â”‚
â”‚  â”‚ â€¢ MLflow API â”‚    â”‚ â€¢ PSI        â”‚    â”‚ â€¢ Run snapshots      â”‚  â”‚
â”‚  â”‚ â€¢ Pred logs  â”‚    â”‚ â€¢ KS-test    â”‚    â”‚ â€¢ Drift history      â”‚  â”‚
â”‚  â”‚ â€¢ Scheduler  â”‚    â”‚ â€¢ JS-div     â”‚    â”‚ â€¢ Alert log          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                     â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      FastAPI Backend                         â”‚  â”‚
â”‚  â”‚         REST + WebSocket Â· OpenAPI Docs Â· Auth               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               React Dashboard (Vite + Recharts)              â”‚  â”‚
â”‚  â”‚    Live metrics Â· Drift charts Â· Alert feed Â· Run explorer   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                          â”‚
         â–¼                                          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ MLflow      â”‚                          â”‚  Alert Sinks  â”‚
  â”‚ Tracking    â”‚                          â”‚  Slack/PD/HTTPâ”‚
  â”‚ Server      â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

**Pluggable by default.** Every major component â€” storage, alerting, drift algorithms â€” is backed by an abstract interface. Swap SQLite for PostgreSQL with one config change. Add a new drift metric by implementing a single abstract method.

**No MLflow coupling beyond the API.** The ingestion engine treats MLflow as a data source, not a dependency. If your team switches tracking tools, only the ingestion adapter changes.

**Pipeline over magic.** Data flows through explicit, testable stages: ingest â†’ transform â†’ store â†’ alert. No hidden side effects. Each stage has its own module, its own tests, and clear inputs/outputs.

---

## Project Structure

```
mlflow-sentinel/
â”‚
â”œâ”€â”€ src/                          # Core Python package
â”‚   â”œâ”€â”€ ingestion/                # MLflow polling & log ingestion
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mlflow_client.py      # MLflow REST API wrapper
â”‚   â”‚   â”œâ”€â”€ log_ingester.py       # Prediction log file reader
â”‚   â”‚   â””â”€â”€ scheduler.py          # APScheduler-based polling loop
â”‚   â”‚
â”‚   â”œâ”€â”€ transformation/           # Data normalization & drift detection
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ normalizer.py         # Schema normalization for run data
â”‚   â”‚   â”œâ”€â”€ drift_detector.py     # PSI, KS-test, JS-divergence
â”‚   â”‚   â””â”€â”€ baseline_manager.py   # Training distribution snapshots
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                  # Pluggable storage adapters
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py               # Abstract StorageAdapter interface
â”‚   â”‚   â”œâ”€â”€ sqlite_adapter.py     # SQLite (dev/local)
â”‚   â”‚   â””â”€â”€ postgres_adapter.py   # PostgreSQL (production)
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/               # Alerting & notification
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ alert_engine.py       # Threshold evaluation & routing
â”‚   â”‚   â””â”€â”€ sinks/
â”‚   â”‚       â”œâ”€â”€ slack.py          # Slack webhook sink
â”‚   â”‚       â”œâ”€â”€ pagerduty.py      # PagerDuty Events API sink
â”‚   â”‚       â””â”€â”€ http.py           # Generic HTTP webhook sink
â”‚   â”‚
â”‚   â””â”€â”€ api/                      # FastAPI application
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py               # App factory, middleware, lifespan
â”‚       â”œâ”€â”€ routers/
â”‚       â”‚   â”œâ”€â”€ runs.py           # /api/v1/runs endpoints
â”‚       â”‚   â”œâ”€â”€ drift.py          # /api/v1/drift endpoints
â”‚       â”‚   â””â”€â”€ alerts.py         # /api/v1/alerts endpoints
â”‚       â”œâ”€â”€ schemas.py            # Pydantic request/response models
â”‚       â””â”€â”€ websocket.py          # WebSocket manager for live updates
â”‚
â”œâ”€â”€ dashboard/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ DriftChart.jsx    # Recharts drift timeline
â”‚   â”‚   â”‚   â”œâ”€â”€ RunExplorer.jsx   # Searchable run table
â”‚   â”‚   â”‚   â”œâ”€â”€ AlertFeed.jsx     # Live alert stream
â”‚   â”‚   â”‚   â””â”€â”€ MetricCard.jsx    # KPI summary cards
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.js   # WebSocket connection hook
â”‚   â”‚   â”‚   â””â”€â”€ useMetrics.js     # SWR data fetching hook
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                     # Pure unit tests (no I/O)
â”‚   â”‚   â”œâ”€â”€ test_drift_detector.py
â”‚   â”‚   â”œâ”€â”€ test_normalizer.py
â”‚   â”‚   â””â”€â”€ test_alert_engine.py
â”‚   â””â”€â”€ integration/              # Integration tests with test containers
â”‚       â”œâ”€â”€ test_pipeline.py
â”‚       â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_demo_data.py         # Populate DB with realistic fake data
â”‚   â””â”€â”€ generate_baseline.py     # Create a training baseline snapshot
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api            # API service image
â”‚   â”œâ”€â”€ Dockerfile.dashboard      # Dashboard build image
â”‚   â””â”€â”€ docker-compose.yml        # Full stack orchestration
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md           # Deep-dive architecture doc
â”‚   â”œâ”€â”€ configuration.md          # All config options explained
â”‚   â”œâ”€â”€ drift_algorithms.md       # Math behind drift detection
â”‚   â””â”€â”€ api_reference.md          # Auto-generated from OpenAPI
â”‚
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                # Lint, test, coverage on PR
â”‚   â”‚   â””â”€â”€ release.yml           # Docker build & push on tag
â”‚   â””â”€â”€ ISSUE_TEMPLATE/
â”‚       â”œâ”€â”€ bug_report.md
â”‚       â””â”€â”€ feature_request.md
â”‚
â”œâ”€â”€ config.example.yaml           # Annotated configuration template
â”œâ”€â”€ docker-compose.yml            # Symlink â†’ docker/docker-compose.yml
â”œâ”€â”€ pyproject.toml                # Package metadata & tool config
â”œâ”€â”€ requirements.txt              # Runtime dependencies
â”œâ”€â”€ requirements-dev.txt          # Dev/test dependencies
â””â”€â”€ README.md
```

---

## Quickstart

### Prerequisites

- Docker & Docker Compose
- A running MLflow tracking server (or use the included demo)

### Option 1 â€” Full Stack with Docker (Recommended)

```bash
# Clone the repo
git clone https://github.com/yourusername/mlflow-sentinel.git
cd mlflow-sentinel

# Copy and configure
cp config.example.yaml config.yaml
# Edit config.yaml â€” set your MLFLOW_TRACKING_URI at minimum

# Launch everything
docker compose up -d

# Seed the dashboard with realistic demo data (optional)
docker compose exec api python scripts/seed_demo_data.py
```

Then open:
- **Dashboard** â†’ http://localhost:5173
- **API Docs** â†’ http://localhost:8000/docs

### Option 2 â€” Local Development

```bash
# Python environment
python -m venv .venv
source .venv/bin/activate       # Windows: .venv\Scripts\activate
pip install -r requirements-dev.txt

# Configure
cp config.example.yaml config.yaml
# Edit config.yaml

# Run the API
uvicorn src.api.main:app --reload --port 8000

# In another terminal, run the pipeline
python -m src.ingestion.scheduler

# Frontend
cd dashboard
npm install
npm run dev
```

---

## Configuration

All configuration lives in `config.yaml`. Environment variables override any key using the `SENTINEL_` prefix.

```yaml
mlflow:
  tracking_uri: "http://localhost:5000"   # Your MLflow server
  poll_interval_seconds: 60               # How often to check for new runs
  experiments:                            # Filter to specific experiments
    - "production-models"
    - "staging-*"                         # Glob patterns supported

storage:
  backend: sqlite                         # sqlite | postgres
  sqlite:
    path: "./sentinel.db"
  postgres:
    dsn: "postgresql://user:pass@host/db" # Or use SENTINEL_POSTGRES_DSN env var

drift:
  algorithms: [psi, ks_test, js_divergence]  # Enable/disable per algorithm
  thresholds:
    psi: 0.2                              # PSI > 0.2 = significant drift
    ks_test_pvalue: 0.05                  # KS p-value threshold
    js_divergence: 0.1

alerting:
  enabled: true
  cooldown_minutes: 30                    # Suppress repeated alerts
  sinks:
    slack:
      enabled: true
      webhook_url: "${SENTINEL_SLACK_WEBHOOK}"   # From env var
    pagerduty:
      enabled: false
      routing_key: "${SENTINEL_PD_ROUTING_KEY}"

api:
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["http://localhost:5173"]
```

---

## Drift Detection â€” How It Works

MLflow-Sentinel compares live prediction feature distributions against a **baseline snapshot** captured at training time. Three complementary algorithms are run on every evaluation window:

| Algorithm | What It Catches | When to Use |
|---|---|---|
| **Population Stability Index (PSI)** | Gradual population shifts | Tabular features, binnable data |
| **Kolmogorov-Smirnov Test** | Any distributional difference | Continuous features |
| **Jensen-Shannon Divergence** | Symmetric distribution distance | Categorical or mixed features |

A drift event is recorded when any enabled algorithm exceeds its configured threshold. Multiple signals on the same window are correlated into a single event with a computed severity score.

See [`docs/drift_algorithms.md`](docs/drift_algorithms.md) for the full mathematical treatment and worked examples.

---

## API Reference

The FastAPI backend auto-generates interactive docs. Key endpoints:

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/v1/runs` | List ingested MLflow runs with filters |
| `GET` | `/api/v1/runs/{run_id}` | Full run detail with metrics history |
| `GET` | `/api/v1/drift` | Drift events, paginated, with severity filter |
| `GET` | `/api/v1/drift/summary` | Aggregated drift stats per experiment |
| `POST` | `/api/v1/baseline` | Register a new training baseline |
| `GET` | `/api/v1/alerts` | Alert history with resolution status |
| `WS` | `/ws/live` | WebSocket stream for real-time dashboard updates |

Full reference at [`docs/api_reference.md`](docs/api_reference.md) or `/docs` when running.

---

## Running Tests

```bash
# Full test suite with coverage
pytest --cov=src --cov-report=term-missing

# Unit tests only (fast, no containers needed)
pytest tests/unit/ -v

# Integration tests (requires Docker for test containers)
pytest tests/integration/ -v

# Specific module
pytest tests/unit/test_drift_detector.py -v
```

Coverage is enforced at 80% via CI. PRs that drop below will fail the check.

---

## Contributing

Contributions are welcome. Please read [`CONTRIBUTING.md`](CONTRIBUTING.md) before opening a PR.

**Adding a new drift algorithm:**
1. Implement `BaseDriftAlgorithm` in `src/transformation/drift_detector.py`
2. Add configuration schema entry in `src/api/schemas.py`
3. Register in the algorithm registry at the bottom of `drift_detector.py`
4. Add unit tests in `tests/unit/test_drift_detector.py`

**Adding a new alert sink:**
1. Implement `BaseAlertSink` in a new file under `src/monitoring/sinks/`
2. Register in `src/monitoring/alert_engine.py`
3. Add config block to `config.example.yaml`

---

## Roadmap

- [ ] **v0.2** â€” Prometheus metrics endpoint (`/metrics`) for Grafana integration
- [ ] **v0.3** â€” SHAP-based feature importance drift (not just distribution drift)
- [ ] **v0.4** â€” Multi-tenant support with API key auth
- [ ] **v1.0** â€” Kubernetes Helm chart

---

## License

MIT Â© 2026. See [LICENSE](LICENSE) for details.

---

<div align="center">
Built to close the gap between model training and production confidence.
</div>
